{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Завантажити набiр зображень типу MNIST.\n",
        "2. Виконати пiдготовку даних для навчання - за необхiдностi, залежно вiд\n",
        "вхiдного набору.\n",
        "3. Розбити данi на навчальну i перевiрочну множини у спiввiдношеннi 80%:\n",
        "20%.\n",
        "4. Побудувати i навчити базову модель з єдиним вихiдним шаром softmax.Для створення моделi реалiзувати власний клас. Ваги iнiцiалiзувати не-\n",
        "великими випадковими значеннями, якi нормально розподiленi з нульо-\n",
        "вим середнiм та одиничною дисперсiєю.\n",
        "5. Побудувати глибокi моделi з кiлькома скритими шарами ReLU або tanh.\n",
        "6. Моделi iз симетричними функцiями активацiї tanh навчити методом ґра-\n",
        "дiєнтного спуску, використовуючи iнiцiалiзацiю ваг Глоро.\n",
        "7. Моделi iз несиметричними функцiями активацiї ReLU навчити методом\n",
        "ґрадiєнтного спуску, використовуючи iнiцiалiзацiю ваг Хе.\n",
        "8. Для усiх моделей побудувати:\n",
        "• графiки змiни значень функцiї втрат на тренувальнiй i перевiро-\n",
        "чнiй множинах по мiрi навчання моделi, тобто залежно вiд кiлькостi епох,\n",
        "• графiки змiни показника accuracy на тренувальнiй i перевiрочнiй\n",
        "множинах по мiрi навчання моделi.\n",
        "Для вiдслiдковування пiд час навчання значень функцiї втрат i пока-\n",
        "зника accuracy можна використати функцiю tf.summary.scalar().\n",
        "9. Пiдiбрати значення гiперпараметра швидкостi навчання. Для вiдображе-\n",
        "ння кривих навчання та вказаних вище графiкiв використати TensorBoard.\n",
        "10. Який метод iнiцiалiзацiї: традицiйний чи Глоро / Хе дає меншi значення\n",
        "показника accuracy?\n",
        "11. Чи має мiсце перенавчання побудованих моделей?\n",
        "12. Зберегти контрольнi точки через фiксованi iнтервали пiд час навчан-\n",
        "ня. В кiнцi навчання зберегти результуючi моделi. Вiдновити останню контрольну точку при запуску моделi, якщо навчання було перервано.\n",
        "13. Обрати для нейронiв скритих шарiв рiзнi функцiї активацiї: LeakyReLU,\n",
        "Parametric LeakyReLU, ELU. Спробувати з’ясувати чи впливає вибiр\n",
        "функцiї активацiї на:\n",
        "• час навчання мережi,\n",
        "• якiсть роботи мережi на перевiрочнiй множинi,\n",
        "• час надання прогнозу мережею.\n",
        "14. Замiсть методу ґрадiєнтного спуску використати один з адаптивних ме-\n",
        "тодiв: прискорений градiєнт Нестерова, Adagrad, Adadelta, Adam, ваги iнiцiалiзувати наведеними вище способами. Побудувати аналогiчнi гра-\n",
        "фiки змiни значень функцiї втрат та змiни показника accuracy.\n",
        "15. Чи покращилася якiсть навчання при використаннi адаптивного алго-\n",
        "ритму оптимiзацiї?\n",
        "16. Для однiєї з мереж додати нормалiзацiю за мiнi-батчами перед кожним\n",
        "шаром.\n",
        "• Перевiрити чи стала мережа менш чутливою до способу iнiцiалiзацiї\n",
        "ваг.\n",
        "• Чи прискорюється процес навчання мережi пiсля додавання такої\n",
        "нормалiзацiї перед кожним шаром?\n",
        "• Обрати бiльшi значення швидкостi навчання. Що можна сказати\n",
        "про якiсть навчання?\n",
        "• Зменшується чи збiльшується час надання прогнозу такою мере-\n",
        "жею?\n",
        "17. Додати до моделей один/ декiлька шарiв дропауту. Пiдiбрати значення\n",
        "p - iмовiрностi вiдключення нейронiв.\n",
        "• Вiдобразити у TensorBoard графiки, якi iлюструють оцiнки якостi\n",
        "навчання мережi на навчальнiй та перевiрочнiй множинах. Зробити\n",
        "висновки щодо якостi навчання мережi з i без використання дропа-\n",
        "ута.\n",
        "• Як треба змiнювати значення iмовiрностi p якщо мережа перена-\n",
        "вчається?\n",
        "18. Реалiзувати ще один спосiб регуляризацiї мереж - ранню зупинку навча-\n",
        "ння мережi.\n",
        "19. Обмежити ваги мережi, застосовуючи регуляризацiю за l1, l2 та max-\n",
        "нормами.\n",
        "20. Обрати найкращу модель за метриками якостi F1 (f1-score) та AUC.\n",
        "21. Використати обрану модель для розпiзнавання одного iз зображень пе-\n",
        "ревiрочної множини.\n",
        "22. Спробувати створити нове зображення, подiбне до зображень у заданому\n",
        "наборi даних. Розпiзнати це зображення за допомогою обраної найкра-\n",
        "щої моделi.\n",
        "23. Використовуючи багатошаровий персептрон, спробувати класифiкувати\n",
        "набiр кольорових зображень типу CIFAR10 (згiдно з варiантом нижче).\n",
        "Впевнитися, що багатошаровий персептрон не справляється з такою за-\n",
        "дачею."
      ],
      "metadata": {
        "id": "QKU-Pd5vLofg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Food Images (Food-101)"
      ],
      "metadata": {
        "id": "STGta8LiweN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "TZwTpnEnMBMQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow_io as tfio\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import collections\n",
        "from collections import defaultdict\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import glob\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from shutil import copy\n",
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, LeakyReLU\n",
        "from tensorflow.keras.initializers import RandomNormal, HeNormal\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n"
      ],
      "metadata": {
        "id": "qk1Ctp6hLw1k"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Підключаємо набір даних та розбиваємо його на навчальний та перевірочний набори"
      ],
      "metadata": {
        "id": "FuIZtw5I5P7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_directory = '/content/drive/MyDrive/food data/train'\n",
        "test_directory = '/content/drive/MyDrive/food data/test'\n",
        "\n",
        "# Define the image size and batch size\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Load the training dataset with labels\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_directory,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the testing dataset with labels\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_directory,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='categorical'\n",
        ")\n",
        "\n",
        "# Extract the class names\n",
        "class_names = train_dataset.class_names\n",
        "\n",
        "# Print the class names\n",
        "print(\"Class Names:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AywhEnURqJ4i",
        "outputId": "067b52da-b5ca-4b9b-f043-53daa6b09368"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2310 files belonging to 3 classes.\n",
            "Found 700 files belonging to 3 classes.\n",
            "Class Names: ['apple_pie', 'fish_and_chips', 'ice_cream']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далі ми використовуємо послідовний клас моделі Sequential для створення порожньої моделі. Додаємо шари за допомогою add. Для компіляціїї використовуємо метод compile де задаємо оптимізатор Adam та функцію втрати. \n",
        "Для навчання використовуємо fit. Передаємо дані для тренувального та валідаційного наборів та об'єкти зворотніх зв'язів."
      ],
      "metadata": {
        "id": "B-TWt25X7n2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#прямого розповсюдження\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(224, 224, 3)))\n",
        "model.add(Dense(3, activation='softmax', kernel_initializer=RandomNormal(mean=0.0, stddev=1.0)))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=tf.losses.CategoricalCrossentropy(),\n",
        "              metrics=[tf.metrics.Accuracy(), tf.metrics.AUC(), tf.metrics.Precision(), tf.metrics.Recall()])\n",
        "\n",
        "# Define the callbacks\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
        "checkpoint_callback = ModelCheckpoint('./checkpoints/model_checkpoint.h5', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=[tensorboard_callback, checkpoint_callback],\n",
        "                    epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTONdMGgvrAO",
        "outputId": "c2b82afc-d0fa-4615-c925-e6f9543715e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 558s 7s/step - loss: 15602.7061 - accuracy: 0.3874 - auc_4: 0.5406 - f1_score: 0.3890 - val_loss: 13569.9053 - val_accuracy: 0.4057 - val_auc_4: 0.5543 - val_f1_score: 0.4023\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 13s 164ms/step - loss: 11434.9346 - accuracy: 0.4394 - auc_4: 0.5795 - f1_score: 0.4416 - val_loss: 15404.8428 - val_accuracy: 0.3814 - val_auc_4: 0.5361 - val_f1_score: 0.3597\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 12s 159ms/step - loss: 10227.3594 - accuracy: 0.4571 - auc_4: 0.5926 - f1_score: 0.4590 - val_loss: 11815.3184 - val_accuracy: 0.4029 - val_auc_4: 0.5527 - val_f1_score: 0.3955\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 12s 142ms/step - loss: 9067.5078 - accuracy: 0.4671 - auc_4: 0.6003 - f1_score: 0.4693 - val_loss: 12681.2344 - val_accuracy: 0.3886 - val_auc_4: 0.5414 - val_f1_score: 0.3870\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 13s 162ms/step - loss: 8383.0762 - accuracy: 0.4848 - auc_4: 0.6138 - f1_score: 0.4865 - val_loss: 11170.1699 - val_accuracy: 0.3814 - val_auc_4: 0.5361 - val_f1_score: 0.3831\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 12s 158ms/step - loss: 7864.5176 - accuracy: 0.4909 - auc_4: 0.6184 - f1_score: 0.4931 - val_loss: 10359.2451 - val_accuracy: 0.3957 - val_auc_4: 0.5468 - val_f1_score: 0.3972\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 13s 166ms/step - loss: 7398.3516 - accuracy: 0.4983 - auc_4: 0.6237 - f1_score: 0.5006 - val_loss: 9585.3389 - val_accuracy: 0.4500 - val_auc_4: 0.5875 - val_f1_score: 0.4408\n",
            "Epoch 8/10\n",
            "73/73 [==============================] - 13s 165ms/step - loss: 6763.1558 - accuracy: 0.5182 - auc_4: 0.6389 - f1_score: 0.5201 - val_loss: 9800.1709 - val_accuracy: 0.4614 - val_auc_4: 0.5961 - val_f1_score: 0.4438\n",
            "Epoch 9/10\n",
            "73/73 [==============================] - 11s 139ms/step - loss: 6567.1655 - accuracy: 0.5199 - auc_4: 0.6399 - f1_score: 0.5218 - val_loss: 9675.3633 - val_accuracy: 0.4086 - val_auc_4: 0.5564 - val_f1_score: 0.4016\n",
            "Epoch 10/10\n",
            "73/73 [==============================] - 12s 158ms/step - loss: 6788.2402 - accuracy: 0.5108 - auc_4: 0.6331 - f1_score: 0.5128 - val_loss: 13450.3486 - val_accuracy: 0.3857 - val_auc_4: 0.5393 - val_f1_score: 0.3710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=./logs"
      ],
      "metadata": {
        "id": "HGn2puFgMnG6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Зі скритими шарами і relu\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(224, 224, 3)))\n",
        "model.add(Dense(114, activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(3, activation='softmax', kernel_initializer=HeNormal(), kernel_regularizer=l2(0.01), kernel_constraint=MaxNorm(3.0)))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', AUC(), F1Score(num_classes=3, average='macro')])\n",
        "\n",
        "# Define the callbacks\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
        "checkpoint_callback = ModelCheckpoint('./checkpoints/model_checkpoint.h5', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_callback = EarlyStopping(patience=3)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=[tensorboard_callback, checkpoint_callback, early_stopping_callback],\n",
        "                    epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhE1yaJ0v0KR",
        "outputId": "ee12713e-04fc-4a35-b9e9-e5a4ab0668ff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 42s 546ms/step - loss: 5180.8130 - accuracy: 0.4190 - auc_5: 0.5644 - f1_score: 0.4207 - val_loss: 1380.2352 - val_accuracy: 0.4771 - val_auc_5: 0.6085 - val_f1_score: 0.3799\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 40s 537ms/step - loss: 1605.9432 - accuracy: 0.4797 - auc_5: 0.6106 - f1_score: 0.4814 - val_loss: 749.3631 - val_accuracy: 0.4914 - val_auc_5: 0.6189 - val_f1_score: 0.4980\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 40s 533ms/step - loss: 793.5861 - accuracy: 0.5009 - auc_5: 0.6264 - f1_score: 0.5036 - val_loss: 563.7888 - val_accuracy: 0.5186 - val_auc_5: 0.6386 - val_f1_score: 0.5100\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 41s 536ms/step - loss: 469.1257 - accuracy: 0.5563 - auc_5: 0.6676 - f1_score: 0.5590 - val_loss: 656.0915 - val_accuracy: 0.4186 - val_auc_5: 0.5641 - val_f1_score: 0.3780\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 39s 530ms/step - loss: 1155.9862 - accuracy: 0.4991 - auc_5: 0.6243 - f1_score: 0.5014 - val_loss: 1412.9832 - val_accuracy: 0.4129 - val_auc_5: 0.5597 - val_f1_score: 0.3635\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 39s 531ms/step - loss: 477.6581 - accuracy: 0.5714 - auc_5: 0.6780 - f1_score: 0.5744 - val_loss: 1106.5376 - val_accuracy: 0.4829 - val_auc_5: 0.6121 - val_f1_score: 0.3546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далі будемо використовувати модель Sequential для побудова нейромережі.\n",
        "\n",
        "*   Використовується активаційна функція LeakyReLU з параметром alpha=0.2.\n",
        "*   Модель має два повнозв'язаних шари з 210 та 3 нейронами відповідно.\n",
        "*  Використовуються ініціалізатор 'he_normal' для ініціалізації ваг та регуляризатор L2 з коефіцієнтом 0.01."
      ],
      "metadata": {
        "id": "G1EBVkPe-Wji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=./logs_relu"
      ],
      "metadata": {
        "id": "AhS_VU-ELjk6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LeakyReLU\n",
        "start_time = time.time()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(224, 224, 3)))\n",
        "model.add(Dense(210))\n",
        "model.add(LeakyReLU(alpha=0.2))\n",
        "model.add(Dense(3, activation='softmax', kernel_initializer=HeNormal(), kernel_constraint=MaxNorm(3.0), kernel_regularizer=l2(0.01)))\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', AUC(), F1Score(num_classes=3, average='macro')])\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs_leaky')\n",
        "checkpoint_callback = ModelCheckpoint('./checkpoints/model_leaky_checkpoint.h5', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_callback = EarlyStopping(patience=3)\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=[tensorboard_callback, checkpoint_callback, early_stopping_callback],\n",
        "                    epochs=10)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution Time:\", execution_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeR7DSbf4sOb",
        "outputId": "f97525cf-1153-43f0-e35f-d08c3745bd85"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7f7520f10dc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 63s 838ms/step - loss: 10159.8770 - accuracy: 0.4463 - auc_11: 0.5849 - f1_score: 0.4487 - val_loss: 3869.7886 - val_accuracy: 0.3529 - val_auc_11: 0.5146 - val_f1_score: 0.2603\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 61s 814ms/step - loss: 2605.9797 - accuracy: 0.4671 - auc_11: 0.6002 - f1_score: 0.4677 - val_loss: 2141.3271 - val_accuracy: 0.4800 - val_auc_11: 0.6100 - val_f1_score: 0.3528\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 57s 765ms/step - loss: 2431.5591 - accuracy: 0.5048 - auc_11: 0.6287 - f1_score: 0.5075 - val_loss: 2294.1665 - val_accuracy: 0.4971 - val_auc_11: 0.6229 - val_f1_score: 0.3813\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 57s 773ms/step - loss: 1737.9578 - accuracy: 0.5186 - auc_11: 0.6389 - f1_score: 0.5215 - val_loss: 6482.9043 - val_accuracy: 0.3214 - val_auc_11: 0.4911 - val_f1_score: 0.2389\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 56s 757ms/step - loss: 2257.2590 - accuracy: 0.5433 - auc_11: 0.6577 - f1_score: 0.5455 - val_loss: 2106.3521 - val_accuracy: 0.3943 - val_auc_11: 0.5457 - val_f1_score: 0.3663\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 62s 830ms/step - loss: 1918.0801 - accuracy: 0.5303 - auc_11: 0.6477 - f1_score: 0.5328 - val_loss: 2310.8779 - val_accuracy: 0.4714 - val_auc_11: 0.6049 - val_f1_score: 0.4425\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 58s 782ms/step - loss: 1259.1292 - accuracy: 0.5727 - auc_11: 0.6798 - f1_score: 0.5753 - val_loss: 3503.1128 - val_accuracy: 0.4486 - val_auc_11: 0.5864 - val_f1_score: 0.2809\n",
            "Epoch 8/10\n",
            "73/73 [==============================] - 61s 831ms/step - loss: 1515.4700 - accuracy: 0.5654 - auc_11: 0.6746 - f1_score: 0.5661 - val_loss: 2029.4733 - val_accuracy: 0.4443 - val_auc_11: 0.5828 - val_f1_score: 0.4344\n",
            "Epoch 9/10\n",
            "73/73 [==============================] - 53s 721ms/step - loss: 1856.1255 - accuracy: 0.5576 - auc_11: 0.6689 - f1_score: 0.5592 - val_loss: 2209.7397 - val_accuracy: 0.4257 - val_auc_11: 0.5693 - val_f1_score: 0.4198\n",
            "Epoch 10/10\n",
            "73/73 [==============================] - 56s 750ms/step - loss: 2030.3357 - accuracy: 0.5455 - auc_11: 0.6593 - f1_score: 0.5490 - val_loss: 2059.6204 - val_accuracy: 0.5000 - val_auc_11: 0.6250 - val_f1_score: 0.4856\n",
            "Execution Time: 815.2578177452087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Використовується активаційна функція elu.\n",
        "*   Модель має два повнозв'язаних шари з 118 та 3 нейронами відповідно.\n",
        "*   Використовуються ініціалізатор 'he_normal' для ініціалізації ваг та регуляризатор L2 з коефіцієнтом 0.01.\n"
      ],
      "metadata": {
        "id": "HK178PQV_W7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xDX1__su-7X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=./logs_leaky"
      ],
      "metadata": {
        "id": "WW2XVno5LmJA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#elu\n",
        "start_time = time.time()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(224, 224, 3)))\n",
        "model.add(Dense(118, activation='elu', kernel_initializer=HeNormal(), kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(3, activation='softmax', kernel_initializer=HeNormal(), kernel_constraint=MaxNorm(3.0)))\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', AUC(), F1Score(num_classes=3, average='macro')])\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs_elu')\n",
        "checkpoint_callback = ModelCheckpoint('./checkpoints/model_elu_checkpoint.h5', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_callback = EarlyStopping(patience=3)\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=[tensorboard_callback, checkpoint_callback, early_stopping_callback],\n",
        "                    epochs=10)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution Time:\", execution_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDDdDwJ14vqu",
        "outputId": "ce9786b4-7dff-4567-f8eb-f2a4292456a8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 42s 548ms/step - loss: 4034.8940 - accuracy: 0.4173 - auc_8: 0.5640 - f1_score: 0.4173 - val_loss: 2583.7893 - val_accuracy: 0.4286 - val_auc_8: 0.5714 - val_f1_score: 0.2060\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 41s 557ms/step - loss: 961.1415 - accuracy: 0.4723 - auc_8: 0.6048 - f1_score: 0.4735 - val_loss: 937.2454 - val_accuracy: 0.4586 - val_auc_8: 0.5939 - val_f1_score: 0.3100\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 48s 648ms/step - loss: 994.3906 - accuracy: 0.4498 - auc_8: 0.5874 - f1_score: 0.4506 - val_loss: 763.9196 - val_accuracy: 0.4114 - val_auc_8: 0.5592 - val_f1_score: 0.3913\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 42s 561ms/step - loss: 517.5018 - accuracy: 0.5476 - auc_8: 0.6619 - f1_score: 0.5494 - val_loss: 657.0535 - val_accuracy: 0.4971 - val_auc_8: 0.6236 - val_f1_score: 0.3852\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 42s 564ms/step - loss: 599.9960 - accuracy: 0.4931 - auc_8: 0.6200 - f1_score: 0.4937 - val_loss: 1149.5302 - val_accuracy: 0.4543 - val_auc_8: 0.5914 - val_f1_score: 0.3034\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 43s 585ms/step - loss: 365.1872 - accuracy: 0.5675 - auc_8: 0.6762 - f1_score: 0.5686 - val_loss: 582.2158 - val_accuracy: 0.3557 - val_auc_8: 0.5163 - val_f1_score: 0.3004\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 42s 570ms/step - loss: 226.3605 - accuracy: 0.5996 - auc_8: 0.7001 - f1_score: 0.6006 - val_loss: 403.1879 - val_accuracy: 0.4586 - val_auc_8: 0.5959 - val_f1_score: 0.3860\n",
            "Epoch 8/10\n",
            "73/73 [==============================] - 42s 563ms/step - loss: 314.5877 - accuracy: 0.5593 - auc_8: 0.6701 - f1_score: 0.5587 - val_loss: 903.9886 - val_accuracy: 0.3986 - val_auc_8: 0.5510 - val_f1_score: 0.3464\n",
            "Epoch 9/10\n",
            "73/73 [==============================] - 46s 623ms/step - loss: 283.3937 - accuracy: 0.5580 - auc_8: 0.6699 - f1_score: 0.5598 - val_loss: 301.5243 - val_accuracy: 0.4429 - val_auc_8: 0.5815 - val_f1_score: 0.4432\n",
            "Epoch 10/10\n",
            "73/73 [==============================] - 45s 600ms/step - loss: 228.6283 - accuracy: 0.5870 - auc_8: 0.6922 - f1_score: 0.5872 - val_loss: 331.4305 - val_accuracy: 0.4571 - val_auc_8: 0.5940 - val_f1_score: 0.3973\n",
            "CPU times: user 6min 38s, sys: 3min 27s, total: 10min 6s\n",
            "Wall time: 10min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Використовується активаційна функція relu.\n",
        "\n",
        "*   Модель має три шари: два повнозв'язаних шари з 125 та 3 нейронами відповідно, а також BatchNormalization шар.\n",
        "*   Використовуються ініціалізатор 'he_normal' для ініціалізації ваг, регуляризатор L2 з коефіцієнтом 0.01 та обмеження ядра MaxNorm з максимальним значенням 3.0.\n",
        "\n"
      ],
      "metadata": {
        "id": "mCiWLHAA_j5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=./logs_elu"
      ],
      "metadata": {
        "id": "xeGlHTuyLqT1"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ReLU \n",
        "start_time = time.time()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(224, 224, 3)))\n",
        "model.add(Dense(125, kernel_initializer=HeNormal(), kernel_regularizer=l2(0.01), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(3, activation='softmax', kernel_constraint=MaxNorm(3.0)))\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', AUC(), F1Score(num_classes=3, average='macro')])\n",
        "\n",
        "# Define the callbacks\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs_batch')\n",
        "checkpoint_callback = ModelCheckpoint('./checkpoints/model_batch_checkpoint.h5', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_callback = EarlyStopping(patience=3)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=[tensorboard_callback, checkpoint_callback, early_stopping_callback],\n",
        "                    epochs=10)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution Time:\", execution_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEMYwJEJ4x5t",
        "outputId": "e6a90592-ee4c-4bdc-9b31-4bf373f9f330"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 51s 666ms/step - loss: 3.9958 - accuracy: 0.3398 - auc_9: 0.5093 - f1_score: 0.3398 - val_loss: 4.4260 - val_accuracy: 0.3629 - val_auc_9: 0.5398 - val_f1_score: 0.3449\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 50s 650ms/step - loss: 3.9861 - accuracy: 0.3433 - auc_9: 0.5116 - f1_score: 0.3432 - val_loss: 4.2186 - val_accuracy: 0.3586 - val_auc_9: 0.5314 - val_f1_score: 0.3481\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 47s 636ms/step - loss: 4.0044 - accuracy: 0.3390 - auc_9: 0.5048 - f1_score: 0.3390 - val_loss: 4.1698 - val_accuracy: 0.3543 - val_auc_9: 0.5270 - val_f1_score: 0.3487\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 46s 612ms/step - loss: 3.9828 - accuracy: 0.3446 - auc_9: 0.5106 - f1_score: 0.3441 - val_loss: 4.1610 - val_accuracy: 0.3600 - val_auc_9: 0.5254 - val_f1_score: 0.3556\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 46s 609ms/step - loss: 3.9905 - accuracy: 0.3377 - auc_9: 0.5104 - f1_score: 0.3377 - val_loss: 4.1723 - val_accuracy: 0.3586 - val_auc_9: 0.5241 - val_f1_score: 0.3546\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 44s 577ms/step - loss: 3.9866 - accuracy: 0.3433 - auc_9: 0.5130 - f1_score: 0.3432 - val_loss: 4.1946 - val_accuracy: 0.3614 - val_auc_9: 0.5240 - val_f1_score: 0.3578\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 45s 592ms/step - loss: 3.9812 - accuracy: 0.3429 - auc_9: 0.5124 - f1_score: 0.3427 - val_loss: 4.2288 - val_accuracy: 0.3614 - val_auc_9: 0.5236 - val_f1_score: 0.3578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=./logs_batch"
      ],
      "metadata": {
        "id": "PWJ3pKV4LtPK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#relu dropout\n",
        "start_time = time.time()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(224, 224, 3)))\n",
        "model.add(Dense(256, kernel_initializer=HeNormal(), kernel_regularizer=l2(0.01), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, kernel_initializer=HeNormal(), kernel_regularizer=l2(0.01), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(3, activation='softmax', kernel_constraint=MaxNorm(3.0)))\n",
        "\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', AUC(), F1Score(num_classes=3, average='macro')])\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs_batch_dropout')\n",
        "checkpoint_callback = ModelCheckpoint('./checkpoints/model_batch_dropout_checkpoint.h5', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_callback = EarlyStopping(patience=3, verbose=1)\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=[tensorboard_callback, checkpoint_callback, early_stopping_callback],\n",
        "                    epochs=10)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution Time:\", execution_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJCesmL4C2v4",
        "outputId": "31d29fb6-371e-4fdc-d8b9-b6fc1f47e0e0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 [==============================] - 74s 974ms/step - loss: 12.1918 - accuracy: 0.4766 - auc_10: 0.6559 - f1_score: 0.4710 - val_loss: 9.1909 - val_accuracy: 0.3743 - val_auc_10: 0.5550 - val_f1_score: 0.2872\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 81s 1s/step - loss: 5.9841 - accuracy: 0.5108 - auc_10: 0.7039 - f1_score: 0.5082 - val_loss: 4.9561 - val_accuracy: 0.4014 - val_auc_10: 0.5722 - val_f1_score: 0.3519\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 73s 985ms/step - loss: 3.8023 - accuracy: 0.5195 - auc_10: 0.7089 - f1_score: 0.5149 - val_loss: 3.4645 - val_accuracy: 0.4257 - val_auc_10: 0.6151 - val_f1_score: 0.4206\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 72s 977ms/step - loss: 3.3357 - accuracy: 0.5216 - auc_10: 0.7155 - f1_score: 0.5182 - val_loss: 3.5522 - val_accuracy: 0.3343 - val_auc_10: 0.5510 - val_f1_score: 0.2688\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 72s 982ms/step - loss: 3.0472 - accuracy: 0.5290 - auc_10: 0.7258 - f1_score: 0.5264 - val_loss: 3.2088 - val_accuracy: 0.3957 - val_auc_10: 0.5861 - val_f1_score: 0.3615\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 71s 959ms/step - loss: 3.7842 - accuracy: 0.5208 - auc_10: 0.7227 - f1_score: 0.5173 - val_loss: 5.9915 - val_accuracy: 0.3343 - val_auc_10: 0.4901 - val_f1_score: 0.2480\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 72s 962ms/step - loss: 5.1280 - accuracy: 0.5433 - auc_10: 0.7271 - f1_score: 0.5398 - val_loss: 6.8948 - val_accuracy: 0.3686 - val_auc_10: 0.4998 - val_f1_score: 0.3137\n",
            "Epoch 8/10\n",
            "73/73 [==============================] - 76s 1s/step - loss: 6.3820 - accuracy: 0.5130 - auc_10: 0.7138 - f1_score: 0.5075 - val_loss: 8.2877 - val_accuracy: 0.3400 - val_auc_10: 0.5228 - val_f1_score: 0.2658\n",
            "Epoch 8: early stopping\n",
            "Execution Time: 614.3293216228485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%tensorboard --logdir=./logs_batch_dropout"
      ],
      "metadata": {
        "id": "ZZU2qXdGHYcM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image = Image.open('/content/drive/MyDrive/food data/fish2.jpg')\n",
        "image = image.resize((224, 224))\n",
        "image = np.array(image) / 255.0\n",
        "image = np.expand_dims(image, axis=0)"
      ],
      "metadata": {
        "id": "MyV5QbjhPjUn"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_elu_checkpoint.h5')"
      ],
      "metadata": {
        "id": "chp3hV-QTDVJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('model_elu_checkpoint.h5')  \n",
        "# Perform prediction\n",
        "prediction = model.predict(image)\n",
        "\n",
        "# Get the predicted class label\n",
        "class_labels = ['apple-pie', 'ice-cream', 'fish_and_chips']\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "print(\"Predicted category:\", predicted_class_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b3mi0sTR3fP",
        "outputId": "1fa830f9-e4ff-42e8-8ad2-b94b4cdfcec8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 110ms/step\n",
            "Predicted category: ice-cream\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найкраще значення f1-store має модель elu, f1 на єпосі сягає 0.58.\n",
        "Я спробувала модель elu на декількох завантажених мною фото, правильно віднесла в 1 з 3 випадків. Але це найкраща модель з усього що є"
      ],
      "metadata": {
        "id": "F7Jz4fNMN8iG"
      }
    }
  ]
}